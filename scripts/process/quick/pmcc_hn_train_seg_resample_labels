#! /usr/bin/env python
from datetime import datetime, timezone
import numpy as np
import os
import pandas as pd
import sys
from tqdm import tqdm

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
sys.path.append(root_dir)

from mymi import dataset
from mymi.dataset.processed import recreate
from mymi import logging
from mymi.transforms import centre_crop_or_pad_3D, resample_3D

DRY_RUN = False
PROCESS_BEFORE = '2021-08-06'
REGIONS = ['Parotid_L', 'Parotid_R']
NEW_SIZE = (128, 128, 96)
NEW_SPACING = (1, 1, 2)
FILENAME_NUM_DIGITS = 5

# Convert cutoff to UNIX timestamp.
date = datetime.strptime(PROCESS_BEFORE, '%Y-%m-%d')
cutoff_ts = date.replace(tzinfo=timezone.utc).timestamp()

# Load seg dataset.
seg_ds_name = 'PMCC-HN-TRAIN-SEG'
seg_ds = dataset.get(seg_ds_name, 'processed')

# Load spacing manifest.
filename = 'spacing-manifest.csv'
filepath = os.path.join(seg_ds.path, filename)
manifest = pd.read_csv(filepath)

# Recreate loc dataset.
loc_ds_name = 'PMCC-HN-TRAIN-LOC'
loc_ds = recreate(loc_ds_name)

# Add samples.
for partition in seg_ds.list_partitions():
    logging.info(f"Processing '{partition}' partition..")
    # Create partition in loc.
    loc_ds.create_partition(partition)

    # Load partition patients.
    indices = seg_ds.partition(partition).list_samples()

    for index in tqdm(indices):
        logging.info(f"index: {index}")
        # Get spacing.
        spacing = eval(manifest[(manifest['partition'] == partition) & (manifest['index'] == index)].iloc[0]['spacing'])
    
        # Get sample regions.
        regions = seg_ds.partition(partition).sample(index).list_regions()
        regions = list(filter(lambda r: r in REGIONS, regions))

        # Load data.
        label = seg_ds.partition(partition).sample(index).label(regions=regions)

        # Resample.
        label = dict((r, resample_3D(d, spacing, NEW_SPACING)) for r, d in label.items())

        if DRY_RUN:
            logging.info(f"Sample: '{index}'.")
            for region, data in label.items():
                filename = f"{index:0{FILENAME_NUM_DIGITS}}.npz"
                filepath = os.path.join(seg_ds.path, 'data', partition, 'labels', region, filename) 
                logging.info(f"\tRegion: '{region}', label shape: '{data.shape}'.")
                logging.info(f"\tWriting to: '{filepath}'.")

                # Apply cutoff criterion.
                ts = os.path.getmtime(filepath)
                if ts < cutoff_ts:
                    logging.info('Passed cutoff criteria.')
                else:
                    logging.info('Skipping due to cutoff criteria.')
        else:
            # Save the label data.
            for region, data in label.items():
                filename = f"{index:0{FILENAME_NUM_DIGITS}}.npz"
                filepath = os.path.join(seg_ds.path, 'data', partition, 'labels', region, filename) 

                # Apply cutoff criterion.
                ts = os.path.getmtime(filepath)
                if ts < cutoff_ts:
                    os.makedirs(os.path.dirname(filepath), exist_ok=True)
                    np.savez_compressed(filepath, data=data)
                else:
                    logging.info('Skipping due to cutoff criteria.')
