#! /usr/bin/env python
from argparse import ArgumentParser
from datetime import datetime
import logging
import numpy as np
import os
import sys
import torch
from tqdm import tqdm

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(root_dir)

from mymi import checkpoint
from mymi import dataset
from mymi.dataset.dicom import DicomDataset, ROIData, RTStructConverter
from mymi.dataset.processed import ProcessedDataset
from mymi.models import SingleChannelUNet
from mymi.predictions import get_patient_segmentation
from mymi.regions import to_255, RegionColours
from mymi import types
from mymi import utils

# Parse arguments.
parser = ArgumentParser(description="""
    Evaluate the segmentation model.
""")
parser.add_argument('--clear-cache', action='store_true', default=False, help='force cache to clear')
parser.add_argument('--dataset', action='store', help='the data to perform inference on', required=True)
parser.add_argument('--localiser', action='store', help='the localiser name', required=True)
parser.add_argument('--localiser-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('--localiser-run', action='store', help='the localiser run', required=True)
parser.add_argument('--localiser-size', action='store', help='the localiser input size', required=True, type=types.parse_size_3D)
parser.add_argument('--localiser-spacing', action='store', help='the localiser input spacing', required=True, type=types.parse_spacing_3D)
parser.add_argument('--log-level', action='store', default='info', help="sets the log level, e.g. 'debug', 'info'")
parser.add_argument('--no-gpu', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('--no-mixed', action='store_true', default=False, help="don't use mixed precision for training")
parser.add_argument('--patient-ids', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('--segmenter', action='store', help='the segmenter name', required=True)
parser.add_argument('--segmenter-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('--segmenter-run', action='store', help='the segmenter run', required=True)
parser.add_argument('--segmenter-size', action='store', help='the segmenter input size', required=True, type=types.parse_size_3D)
parser.add_argument('--segmenter-spacing', action='store', help='the segmenter input spacing', required=True, type=types.parse_spacing_3D)
args = parser.parse_args()

# Configure logging.
log_level = getattr(logging, args.log_level.upper(), None)
utils.configure_logging(log_level)

# Configure device.
if args.no_gpu:
    device = torch.device('cpu')
else:
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
        logging.info('CUDA not available.')
logging.info(f"Using device: {device}.")

# Load localiser model.
localiser = SingleChannelUNet()
localiser = localiser.to(device)
logging.info(f"Using localiser model arch: {localiser.__class__}.")

# Load localiser params.
localiser_state, _ = checkpoint.load(args.localiser, args.localiser_run, checkpoint_name=args.localiser_checkpoint, device=device)
localiser.load_state_dict(localiser_state)
logging.info(f"Loaded localiser with name '{args.localiser}' from training run '{args.localiser_run}'.")

# Load segmenter model.
segmenter = SingleChannelUNet()
segmenter = segmenter.to(device)
logging.info(f"Using segmenter model arch: {segmenter.__class__}.")

# Load segmenter params.
segmenter_state, _ = checkpoint.load(args.segmenter, args.segmenter_run, checkpoint_name=args.segmenter_checkpoint, device=device)
segmenter.load_state_dict(segmenter_state)
logging.info(f"Loaded segmenter with name '{args.segmenter}' from training run '{args.segmenter_run}'.")

# Load test patients from manifest.
ds = DicomDataset(args.dataset) 
ds_proc = ProcessedDataset(args.dataset) 
pats = ds_proc.manifest('test')

# Re/create pred dataset.
pred_ds_name = f"{args.dataset}-pred"
dss = dataset.list()
if pred_ds_name in dss:
    dataset.destroy(pred_ds_name)
dataset.create(pred_ds_name)
ds_pred = DicomDataset(pred_ds_name)

for pat in tqdm(pats):
    # Get segmentation
    seg = get_patient_segmentation(pat, localiser, args.localiser_size, args.localiser_spacing, segmenter, args.segmenter_size, args.segmenter_spacing, clear_cache=args.clear_cache, device=device)

    # Load reference CT dicoms.
    cts = ds.patient(pat).get_cts()

    # Create RTSTRUCT dicom.
    rtstruct = RTStructConverter.create_rtstruct(cts)

    # Create ROI data.
    roi_data = ROIData(
        colour=list(to_255(RegionColours.Parotid_L)),
        data=seg,
        frame_of_reference_uid=rtstruct.ReferencedFrameOfReferenceSequence[0].FrameOfReferenceUID,
        name='Parotid_L'
    )

    # Add ROI.
    RTStructConverter.add_roi(rtstruct, roi_data, cts)

    # Save in new 'pred' dataset.
    filename = f"{pat}.dcm"
    filepath = os.path.join(ds_pred.path, 'raw', filename)
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    rtstruct.save_as(filepath)
