#! /usr/bin/env python
from argparse import ArgumentParser
from datetime import datetime
import logging
import numpy as np
import os
import sys
import torch

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(root_dir)

from mymi import checkpoint
from mymi import dataset
from mymi.dataset.dicom import RTStructConverter
from mymi.models import SingleChannelUNet
from mymi.predictions import get_patient_segmentation
from mymi import utils

# Parse options.
def interval_type(s: str):
    if s == 'epoch':
        return s
    elif s.isdigit():
        return int(s)
    else:
        raise ArgumentTypeError(f"Should be 'epoch' or integer, got '{s}'.")

# Parse arguments.
parser = ArgumentParser(description="""
    Evaluate the segmentation model.
""")
parser.add_argument('-d', '--dataset', action='store', help='the data to perform inference on', required=True)
parser.add_argument('-l', '--log-level', action='store', default='info', help="sets the log level, e.g. 'debug', 'info'")
parser.add_argument('-lc', '--localiser-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('-ln', '--localiser-name', action='store', help='the localiser name', required=True)
parser.add_argument('-lr', '--localiser-run', action='store', help='the localiser run', required=True)
parser.add_argument('-ng', '--no-gpu', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('-nm', '--no-mixed', action='store_true', default=False, help="don't use mixed precision for training")
parser.add_argument('-p', '--patient-ids', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('-sc', '--segmenter-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('-sn', '--segmenter-name', action='store', help='the segmenter name', required=True)
parser.add_argument('-sr', '--segmenter-run', action='store', help='the segmenter run', required=True)
args = parser.parse_args()

# Configure logging.
log_level = getattr(logging, args.log_level.upper(), None)
utils.configure_logging(log_level)

# Configure device.
if args.no_gpu:
    device = torch.device('cpu')
else:
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
        logging.info('CUDA not available.')
logging.info(f"Using device: {device}.")

# Load localiser model.
localiser_size = (128, 128, 96)
localiser_spacing = (1, 1, 3)
localiser = SingleChannelUNet()
localiser = localiser.to(device)
logging.info(f"Using localiser model arch: {localiser.__class__}.")

# Load localiser params.
localiser_state, _ = checkpoint.load(args.localiser_name, args.localiser_run, checkpoint_name=args.localiser_checkpoint, device=device)
localiser.load_state_dict(localiser_state)
logging.info(f"Loaded localiser with name '{args.localiser_name}' from training run '{args.localiser_run}'.")

# Load segmenter model.
segmenter_size = (128, 128, 96)
segmenter_spacing = (1, 1, 3)
segmenter = SingleChannelUNet()
segmenter = segmenter.to(device)
logging.info(f"Using segmenter model arch: {segmenter.__class__}.")

# Load segmenter params.
segmenter_state, _ = checkpoint.load(args.segmenter_name, args.segmenter_run, checkpoint_name=args.segmenter_checkpoint, device=device)
segmenter.load_state_dict(segmenter_state)
logging.info(f"Loaded segmenter with name '{args.segmenter_name}' from training run '{args.segmenter_run}'.")

# Load test patients from manifest.
ds_name = 'HEAD-NECK-RADIOMICS-HN1'
dataset.select(ds_name, type=dataset.types.PROCESSED)
pats = dataset.manifest('test')

# Switch back to main dataset to load CT data.
dataset.select(ds_name)

for pat in pats:
    # Get segmentation
    seg = get_patient_segmentation(pat, localiser, localiser_size, localiser_spacing, segmenter, segmenter_size, segmenter_spacing, clear_cache=args.clear_cache, device=device)
    
    # Create label dict.
    rois = {}
    rois['Parotid_L'] = seg

    # Load reference CT dicoms.
    cts = dataset.patient(pat).ct_data(clear_cache=args.clear_cache)

    # Convert to RTSTRUCT dicom.
    rtstruct = RTStructConverter.create_rtstruct(rois, cts)

    # Save in new 'pred' dataset.

