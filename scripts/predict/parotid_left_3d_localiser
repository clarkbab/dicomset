#! /usr/bin/env python
from argparse import ArgumentParser
from datetime import datetime
import logging
import numpy as np
import os
import sys
import torch
from torchio.transforms import Compose, Resample

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(root_dir)

from mymi import checkpoint
from mymi.models import ParotidLeft3DNet
from mymi.postprocessing import largest_connected_component
from mymi import utils

# Parse options.
def interval_type(s: str):
    if s == 'epoch':
        return s
    elif s.isdigit():
        return int(s)
    else:
        raise ArgumentTypeError(f"Should be 'epoch' or integer, got '{s}'.")

# Parse arguments.
parser = ArgumentParser(description="""
    Evaluate the segmentation model.
""")
parser.add_argument('-d', '--data-path', action='store', help='the data to perform inference on', required=True)
parser.add_argument('-l', '--log-level', action='store', default='info', help="sets the log level, e.g. 'debug', 'info'")
parser.add_argument('-mc', '--model-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('-mn', '--model-name', action='store', help='the model name', required=True)
parser.add_argument('-p', '--print-interval', action='store', type=interval_type, help='how often to print the results')
parser.add_argument('-n', '--name', action='store', help='the run name')
parser.add_argument('-na', '--no-autocast', action='store_true', default=False, help='turn off autocast')
parser.add_argument('-ng', '--no-gpu', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('-nh', '--no-hausdorff', action='store_true', default=False, help='turn off the HD metric')
parser.add_argument('-nr', '--no-record', action='store_true', default=False, help="don't record labels, predictions, figures, etc.")
parser.add_argument('-r', '--run-name', action='store', help='the run name', required=True)
args = parser.parse_args()

# Configure logging.
log_level = getattr(logging, args.log_level.upper(), None)
utils.configure_logging(log_level)

# Determine run name.
if args.name:
    run_name = args.name
else:
    run_name = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')
logging.info(f"Run name: {run_name}.")

# Configure device.
if args.no_gpu:
    device = torch.device('cpu')
else:
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
        logging.info('CUDA not available.')
logging.info(f"Using device: {device}.")

# Create model.
model = ParotidLeft3DNet()
model = model.to(device)
logging.info(f"Using model arch: {model.__class__}.")

# Load model params.
cp = checkpoint.load(args.model_name, args.run_name, checkpoint_name=args.model_checkpoint)
model.load_state_dict(cp['model_state_dict'])
logging.info(f"Loaded model with name '{args.name}' from training run '{args.run_name}'.")

# Create input transforms.
data_res = (512, 512, 212)
input_res = (128, 128, 96)
data_spacing = (1, 1, 3)
input_spacing = tuple((np.array(data_res) / input_res) * data_spacing)
transforms = [
    Resample(input_spacing)
]
logging.info(f"Using transforms '{transforms}'.")
transform = Compose(transforms)

# Create output transform, applied to prediction before post-processing.
output_transforms = [
    Resample(data_spacing)
]
logging.info(f"Using output transforms: '{output_transforms}'.")
output_transform = Compose(output_transforms)

# Load input data.
f = open(args.data_path, 'rb')
data = np.load(f)

# Convert to PyTorch-friendly format.
input = torch.Tensor(data).reshape((1, 1, *data.shape))
input = input.float()
    
# Run inference.
autocast_enabled = not args.no_autocast
with autocast(enabled=autocast_enabled):
    pred = model(input)

# Convert to binary prediction.
pred = pred.argmax(axis=1)

# Move data to CPU for metric calculations.
pred = pred.cpu()

# Transform output prediction.
output_spacing = input_spacing

# Create torchio 'subject'.
affine = np.array([
    [output_spacing[0], 0, 0, 0],
    [0, output_spacing[1], 0, 0],
    [0, 0, output_spacing[2], 1],
    [0, 0, 0, 1]
])
pred = LabelMap(tensor=pred, affine=affine)
subject = Subject(a_segmentation=pred)

# Transform the subject.
output = output_transform(subject)

# Extract results.
pred = output['a_segmentation'].data

# Find the largest connected component.
pred = largest_connected_component(pred)

# Get the bounding box.
bb_min, bb_dim = bounding_box(pred)

# Report results.
print(bb_min, bb_dim)