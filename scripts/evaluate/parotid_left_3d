#! /usr/bin/env python
from argparse import ArgumentParser
from datetime import datetime
import logging
import numpy as np
import os
import sys
import torch
from torchio.transforms import Compose, Resample

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(root_dir)

from mymi import checkpoint
from mymi.evaluation import ModelEvaluator
from mymi.loaders import ParotidLeft3DLoader
from mymi.models import ParotidLeft3DNet
from mymi import utils

# Parse options.
def interval_type(s: str):
    if s == 'epoch':
        return s
    elif s.isdigit():
        return int(s)
    else:
        raise ArgumentTypeError(f"Should be 'epoch' or integer, got '{s}'.")

# Parse arguments.
parser = ArgumentParser(description="""
    Evaluate the segmentation model.
""")
parser.add_argument('-l', '--log-level', action='store', default='info', help="sets the log level, e.g. 'debug', 'info'")
parser.add_argument('-mc', '--model-checkpoint', action='store', default='checkpoint', help='the checkpoint name')
parser.add_argument('-mn', '--model-name', action='store', help='the model name', required=True)
parser.add_argument('-p', '--print-interval', action='store', type=interval_type, help='how often to print the results')
parser.add_argument('-n', '--name', action='store', help='the run name')
parser.add_argument('-ng', '--no-gpu', action='store_true', default=False, help='turn off GPU use')
parser.add_argument('-nh', '--no-hausdorff', action='store_true', default=False, help='turn off the HD metric')
parser.add_argument('-nr', '--no-record', action='store_true', default=False, help="don't record labels, predictions, figures, etc.")
args = parser.parse_args()

# Configure logging.
log_level = getattr(logging, args.log_level.upper(), None)
utils.configure_logging(log_level)

# Determine run name.
if args.name:
    run_name = args.name
else:
    run_name = datetime.now().strftime('%Y_%m_%d_%H_%M_%S')
logging.info(f"Run name: {run_name}.")

# Configure device.
if args.no_gpu:
    device = torch.device('cpu')
else:
    if torch.cuda.is_available():
        device = torch.device('cuda:0')
    else:
        device = torch.device('cpu')
        logging.info('CUDA not available.')
logging.info(f"Using device: {device}.")

# Create model.
model = ParotidLeft3DNet()
model = model.to(device)
logging.info(f"Using model: {model.__class__}.")

# Load model params.
cp = checkpoint.load(args.model_name, checkpoint_name=args.model_checkpoint)
model.load_state_dict(cp['model_state_dict'])
logging.info(f"Loaded model name: {args.name}.")

# Create input transforms.
data_res = (512, 512, 212)
input_res = (128, 128, 96)
data_spacing = (1, 1, 3)
input_spacing = tuple((np.array(data_res) / input_res) * data_spacing)
transforms = [
    Resample(input_spacing)
]
logging.info(f"Using transforms '{transforms}'.")
transform = Compose(transforms)

# Create pred transform - applied to pred before calculating loss, e.g. upsample.
output_transforms = [
    Resample(data_spacing)
]
logging.info(f"Using output transforms: '{output_transforms}'.")
output_transform = Compose(output_transforms)

# Create test loader.
test_loader = ParotidLeft3DLoader.build('test', raw_input=True, raw_label=True, spacing=data_spacing, transform=transform)

# Set evaluator kwargs.
kwargs = {}
kwargs['device'] = device
kwargs['metrics'] = ['dice']
if not args.no_hausdorff:
    append(kwargs['metrics'], 'hausdorff')
kwargs['output_spacing'] = input_spacing
kwargs['output_transform'] = output_transform
if args.no_record:
    kwargs['record'] = False
    logging.info('Not recording evaluation data.')
else:
    logging.info('Recording evaluation data.')
if args.print_interval:
    kwargs['print_interval'] = args.print_interval

# Run evaluator.
evaluator = ModelEvaluator(run_name, test_loader, **kwargs)
evaluator(model)
    