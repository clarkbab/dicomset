#! /usr/bin/env python3
import argparse
import os
import pandas as pd
import sys
import torch

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
sys.path.append(root_dir)

from mymi import dataset
from mymi.dataset import DicomDataset
from mymi import logging
from mymi.metrics import dice
from mymi import utils

# Parse args.
parser = argparse.ArgumentParser(description='Compare contours to ground truth')
parser.add_argument('-c', '--clear-cache', action='store_true', default=False, help='clear the cache')
parser.add_argument('-f', '--filter-errors', action='store_true', default=False, help='filter out patients with known errors')
parser.add_argument('-g', '--ground-truth', action='store', help='the ground truth dataset', required=True)
parser.add_argument('-l', '--log-level', action='store', default='info', help='sets the log level')
parser.add_argument('-p', '--predictions', action='store', help='the predictions', required=True)
args = parser.parse_args()

# Create logger.
logging.config(args.log_level)

# Create ground truth dataset.
gt_ds = DicomDataset(args.ground_truth)

# Load evaluation patients.
pred_ds = DicomDataset(args.predictions, ct_from=args.ground_truth)
pats = pred_ds.list_patients()

# Load up labels.
label_map = gt_ds.label_map(dataset=args.predictions)
internal_labels = list(label_map.internal)
gt_labels = list(label_map[args.ground_truth])
pred_labels = list(label_map[args.predictions])

# Create dataframe.
cols = {
    'pat-id': str,
    'metric': str
}
for label in internal_labels:
    cols[label] = float
df = pd.DataFrame(columns=cols.keys())

# Add metrics for patients.
for pat in pats:
    # Load ground truth.
    try:
        gt_label_data = gt_ds.patient(pat).label_data(clear_cache=args.clear_cache, labels=gt_labels)
    except ValueError as e:
        if args.filter_errors:
            logging.error(f"Error occurred while calling 'label_data' for dataset '{gt_ds.name}', patient '{pat}'.")
            logging.error(f"Error message: {e}")
            continue
        else:
            raise e

    # Load prediction data.
    pred_label_data = pred_ds.patient(pat).label_data(clear_cache=args.clear_cache, labels=pred_labels)

    # Add metrics for each label.
    dice_data = {
        'pat-id': pat,
        'metric': 'dice'
    }
    for internal_label, gt_label, pred_label in zip(internal_labels, gt_labels, pred_labels):
        if gt_label in gt_label_data and pred_label in pred_label_data:
            # Add dice.
            dice_score = dice(pred_label_data[pred_label], gt_label_data[gt_label])
            dice_data[internal_label] = dice_score
        else:
            continue

    # Add row.
    df = df.append(dice_data, ignore_index=True)

print(df)
