#! /usr/bin/env python
import argparse
from argparse import ArgumentParser, ArgumentTypeError
import logging
import matplotlib.pyplot as plt
import numpy as np
import os
import sys
import torch
import torch.nn as nn
import torch.optim as optim

root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(root_dir)

from mymi import models
from mymi import training
from mymi import utils
from mymi.augmentation import transforms as ts
from mymi.loaders import DataLoader, ImageDataset

# Parse options.
def interval_type(s):
    if s == 'epoch':
        return s
    elif s.isdigit():
        return int(s)
    else:
        raise ArgumentTypeError(f"Should be 'epoch' or integer, got '{s}'.")

parser = ArgumentParser(description='Train the segmentation model')
parser.add_argument('-b', '--batch-size', action='store', type=int, default=1, help='sets the batch size, default=1')
parser.add_argument('-e', '--max-epochs', action='store', type=int, help='sets the maximum number of epochs')
parser.add_argument('-l', '--log-level', action='store', default='info', help="sets the log level, e.g. 'debug', 'info'")
parser.add_argument('-n', '--name', action='store', help='sets the run name for Tensorboard')
parser.add_argument('-p', '--print-interval', action='store', type=interval_type, help='iterations between printing')
parser.add_argument('-r', '--record-interval', action='store', type=interval_type, help='iterations between recording')
parser.add_argument('-v', '--validation-interval', action='store', type=interval_type, help='iterations between validation')
args = parser.parse_args()

# Create logger.
log_level = getattr(logging, args.log_level.upper(), None)
utils.configure_logging(log_level)

# Configure device.
device = utils.configure_device()

# Define transforms.
p = 0.5
fill = -1000
angle = 10
translation = 50
scale = (0.8, 1.2)
res = (512, 512) 
transforms = [
    ts.RandomRotation((-angle, angle), fill=fill, p=p),
    ts.RandomTranslation(((-translation, translation), (-translation, translation)), fill=fill, p=p),
    ts.RandomResample((scale, scale), p=p),
    ts.CropOrPad(res, fill=fill)
]
validation_transforms = [
    ts.CropOrPad(res, fill=fill)
]

# Get data loaders.
batch_size = args.batch_size
train_loader = DataLoader.build('train', batch_size=batch_size, transforms=transforms)
validation_loader = DataLoader.build('validate', batch_size=batch_size, transforms=validation_transforms)
test_loader = DataLoader.build('test', batch_size=batch_size, transforms=validation_transforms)

# Create model.
model = models.ParotidNet()
model = model.to(device)

# Define loss.
class_weights = torch.Tensor((1, 4315)).to(device)
loss_fn = nn.NLLLoss(weight=class_weights)

# Define optimiser.
optimiser = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Create model trainer.
kwargs = {
    'device': device
}
if args.max_epochs is not None: kwargs['max_epochs'] = args.max_epochs
if args.print_interval is not None: kwargs['print_interval'] = args.print_interval
if args.record_interval is not None: kwargs['record_interval'] = args.record_interval
if args.validation_interval is not None: kwargs['validation_interval'] = args.validation_interval

trainer = training.ModelTrainer(train_loader, validation_loader, optimiser, loss_fn, **kwargs)
trainer(model)
